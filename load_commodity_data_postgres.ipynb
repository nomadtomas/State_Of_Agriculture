{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, widgets\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://nomadtomas:nomadtomas@localhost:5432/agriculture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load county and state abbreviations \n",
    "county_codes = pd.read_html('https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697')\n",
    "state_abbr = pd.read_excel('data/state_abb.xlsx')\n",
    "state_abbr.columns = ['St_name', 'State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format fips data for merger to commodity dataframes\n",
    "fips = state_abbr.merge(county_codes[0], on=[\"State\"])\n",
    "fips.columns = ['St_name', 'State', 'fips', 'Name']\n",
    "fips['St_name'] = fips['St_name'].map(lambda x: x.upper())\n",
    "fips['Name'] = fips['Name'].map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#county corn data\n",
    "cn_cnt_df = pd.read_csv('data/corn_cnt_2018_2014.csv')\n",
    "cn_cnt_df2 = pd.read_csv('data/corn_cnt_2013_2009.csv')\n",
    "#county cotton data\n",
    "ct_cnt_df = pd.read_csv('data/cotton_cnt_2018_2009.csv')\n",
    "#county soybean data\n",
    "sb_cnt_df = pd.read_csv('data/soybean_cnt_2018_2014.csv')\n",
    "sb_cnt_df2 = pd.read_csv('data/soybean_cnt_2013_2009.csv')\n",
    "#county winter wheat data\n",
    "ww_cnt_df = pd.read_csv('data/ww_cnt_2018_2014.csv')\n",
    "ww_cnt_df2 = pd.read_csv('data/ww_cnt_2013_2009.csv')\n",
    "#county hay alfalfa data\n",
    "hayalf_df = pd.read_csv('data/hayalf_2018_2009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cnt_data(df):\n",
    "    '''\n",
    "    transform dataframe values and features\n",
    "    '''\n",
    "    #select features\n",
    "    cnt_cols = ['Year','Geo Level', 'State',\n",
    "       'State ANSI', 'Ag District', 'Ag District Code', 'County',\n",
    "       'Commodity', 'Data Item', 'Value']\n",
    "    \n",
    "    df = df.loc[:,cnt_cols]\n",
    "    #renamed columns to fit python friendly syntax\n",
    "    df.columns = ['year', 'geo_level', 'state',\n",
    "           'state_ansi', 'ag_district', 'ag_district_code', 'county',\n",
    "           'commodity', 'data_item', 'value']\n",
    "    #removed suppressed rows which number has been other to the aggregate 'other'\n",
    "    df = df[df['value'] != ' (D)']\n",
    "    df['value']= df['value'].map(lambda x: x.replace(',', '')).astype(float)\n",
    "    #merged fips data into the commodity df\n",
    "    df = df.merge(fips, how='left', left_on=['state', 'county'], right_on=['St_name', 'Name'])\n",
    "    df.drop(['State', 'St_name', 'Name'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data from dataframe\n",
    "cn_cnt_df = clean_cnt_data(cn_cnt_df)\n",
    "cn_cnt_df2 = clean_cnt_data(cn_cnt_df2)\n",
    "ct_cnt_df = clean_cnt_data(ct_cnt_df)\n",
    "sb_cnt_df = clean_cnt_data(sb_cnt_df)\n",
    "sb_cnt_df2 = clean_cnt_data(sb_cnt_df2)\n",
    "ww_cnt_df = clean_cnt_data(ww_cnt_df)\n",
    "ww_cnt_df2 = clean_cnt_data(ww_cnt_df2)\n",
    "hayalf_df = clean_cnt_data(hayalf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe to postgressql\n",
    "cn_cnt_df.to_sql('corn', engine, if_exists='append', index=False)\n",
    "cn_cnt_df2.to_sql('corn', engine, if_exists='append', index=False)\n",
    "ct_cnt_df.to_sql('cotton', engine, if_exists='append', index=False)\n",
    "sb_cnt_df.to_sql('soybean', engine, if_exists='append', index=False)\n",
    "sb_cnt_df2.to_sql('soybean', engine, if_exists='append', index=False)\n",
    "ww_cnt_df.to_sql('winter_wheat', engine, if_exists='append', index=False)\n",
    "ww_cnt_df2.to_sql('winter_wheat', engine, if_exists='append', index=False)\n",
    "hayalf_df.to_sql('hay_alf', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state level commodity data\n",
    "st_df = pd.read_csv('data/cn_ct_sb_ww_st_2018_2009.csv')\n",
    "hay_st_df = pd.read_csv('data/hayalf_2018_2009.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_st_data(df):\n",
    "    '''\n",
    "    transform dataframe values and features\n",
    "    '''\n",
    "    #select state level features\n",
    "    st_col = ['Program', 'Year', 'Geo Level', 'State',\n",
    "       'Commodity', 'Data Item', 'Domain', 'Domain Category', 'Value']\n",
    "    \n",
    "    df = df.loc[:,st_col]\n",
    "    #renamed columns to fit python friendly syntax\n",
    "    df.columns = ['program', 'year', 'geo_level', 'state',\n",
    "                  'commodity', 'data_item', 'domain', 'domain_category', 'value']\n",
    "    #removed suppressed rows which number has been other to the aggregate 'other'\n",
    "    df = df[df['value'] != ' (D)']\n",
    "    df['value']= df['value'].map(lambda x: x.replace(',', '')).astype(float)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform data from dataframe\n",
    "hay_st_df = clean_st_data(hay_st_df)\n",
    "st_df = clean_st_data(st_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataframe to postgressql\n",
    "hay_st_df.to_sql('state_num', engine, if_exists='append', index=False)\n",
    "st_df.to_sql('state_num', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
